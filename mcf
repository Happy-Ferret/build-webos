#!/usr/bin/python3
# Copyright (c) 2008-2014 LG Electronics, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


from __future__ import with_statement, print_function, unicode_literals, absolute_import, division

import argparse
import errno
import logging
import os
import subprocess
import sys
import re
import shlex
from time import gmtime, strftime
import shutil
import glob

__version__ = "3.0.4"

logger = logging.getLogger(__name__)

submodules = {}
CLEAN = False
REMOTE = "origin"

def echo_check_call(todo, verbosity, cwd=None):
    if verbosity:
        cmd = 'set -x; ' + todo
    else:
        cmd = todo

    return subprocess.check_call(cmd,
                                 stdout=sys.stdout,
                                 stderr=sys.stderr,
                                 shell=True,
                                 cwd=cwd)

def echo_check_call2(todo, verbosity=False):
    if verbosity:
        cmd = 'set -x; ' + todo
    else:
        cmd = todo

    logger.debug(cmd)

    return str(subprocess.check_output(cmd, shell=True), encoding='utf-8', errors='strict')

def echo_cmd(cmd):
    logger.debug(cmd)
    return cmd

def enable_clean():
    print('Warning: running in clean non-interactive mode, all possible local changes and untracked files will be removed')
    global CLEAN
    CLEAN = True

def enable_debug():
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.DEBUG)
    f = logging.Formatter('%(asctime)s %(levelname)s %(name)s %(message)s', datefmt='%Y-%m-%dT%H:%M:%S')

    s = logging.StreamHandler()
    s.setLevel('DEBUG')

    s.setFormatter(f)
    logging.getLogger('').addHandler(s)

# Essentially, mcf parses options, creates mcf.status, and runs mcf.status.

def process_file(ifile, ofile, replacements):
    statusfilename = ifile
    statusfile = open(statusfilename, 'r')
    status = statusfile.read()
    statusfile.close()

    for i, j in replacements:
        status = status.replace(i, j)

    statusfile = open(ofile, 'w')
    statusfile.write(status)
    statusfile.close()
    return

def getopts():
    mcfcommand_option = '--command'
    mcfcommand_dest = 'mcfcommand'
    mcfcommand_choices = ['configure', 'update']
    mcfcommand_default = 'configure'

    # Just parse the --command argument here, so that we can select a parser
    mcfcommand_parser = argparse.ArgumentParser(add_help=False)
    mcfcommand_parser.add_argument(mcfcommand_option, dest=mcfcommand_dest, choices=mcfcommand_choices, default=mcfcommand_default)
    mcfcommand_parser_result = mcfcommand_parser.parse_known_args()
    mcfcommand = mcfcommand_parser_result[0].mcfcommand

    # Put --command back in (as the first option) so that the main parser sees everything
    arglist = [mcfcommand_option, mcfcommand ] + mcfcommand_parser_result[1]

    parser = argparse.ArgumentParser()

    general = parser.add_argument_group('General Options')

    verbosity = general.add_mutually_exclusive_group()

    verbosity.add_argument('-s', '--silent', dest='verbose',
                         action='store_false', default=False,
                         help='work silently')

    verbosity.add_argument('-v', '--verbose', dest='verbose',
                       action='store_true', default=False,
                       help='work verbosely')

    general.add_argument('-c', '--clean', dest='clean', action='store_true', default=False, help='clean checkout - WARN: removes all local changes')
    general.add_argument('-x', '--trace', dest='trace', action='store_true', default=False, help='trace')
    general.add_argument('-V', '--version', action='version', version='%(prog)s {0}'.format(__version__), help='print version and exit')

    general.add_argument(mcfcommand_option, dest=mcfcommand_dest, choices=mcfcommand_choices, default=mcfcommand_default,
                              help='command to mcf; if update is given, none of the remaining options nor MACHINE can be specified (default: %(default)s)')

    if mcfcommand == 'configure':
        variations = parser.add_argument_group('Build Instructions')

        variations.add_argument('-p', '--enable-parallel-make', dest='parallel_make', type=int, default=0,
                                help='maximum number of parallel tasks each submake of bitbake should spawn (default: 0 = 2x the number of processor cores)')

        variations.add_argument('-b', '--enable-bb-number-threads', dest='bb_number_threads', type=int, default=0,
                                help='maximum number of bitbake tasks to spawn (default: 0 = 2x the number of processor cores))')

        icecc = parser.add_argument_group('ICECC Configuration')

        icecc.add_argument('--enable-icecc', dest='enable_icecc', action='store_true', default=True,
                           help='enable build to use ICECC (default: True)')

        icecc.add_argument('--disable-icecc', dest='disable_icecc', action='store_true', default=False,
                           help='disable build from using ICECC (default: False = use ICECC)')

        icecc.add_argument('--enable-icecc-parallel-make', dest='icecc_parallel_make', type=int, default=0,
                           help='Number of parallel threads for ICECC build (default: 0 = 4x the number of processor cores))')

        icecc_advanced = parser.add_argument_group('ICECC Advanced Configuration')

        icecc_advanced.add_argument('--enable-icecc-user-package-blacklist', dest='icecc_user_package_blacklist', action='append',
                           help='Space separated list of components/recipes to be excluded from using ICECC  (default: None)')

        icecc_advanced.add_argument('--enable-icecc-user-class-blacklist', dest='icecc_user_class_blacklist', action='append',
                           help='Space separated list of components/recipes class to be excluded from using ICECC  (default: None)')

        icecc_advanced.add_argument('--enable-icecc-user-package-whitelist', dest='icecc_user_package_whitelist', action='append',
                           help='Space separated list of components/recipes to be forced to use ICECC  (default: None)')

        icecc_advanced.add_argument('--enable-icecc-location', dest='icecc_location', default='',
                           help='location of ICECC tool  (default: None)')

        icecc_advanced.add_argument('--enable-icecc-env-exec', dest='icecc_env_exec', default='',
                           help='location of ICECC environment script  (default: None)')


        partitions = parser.add_argument_group('Source Identification')

        mirrors = parser.add_argument_group('Networking and Mirrors')

        network = mirrors.add_mutually_exclusive_group()

        network.add_argument('--disable-network', dest='network', action='store_false', default=True,
                             help='disable fetching through the network (default: False)')

        network.add_argument('--enable-network', dest='network', action='store_true', default=True,
                             help='enable fetching through the network (default: True)')

        # use shorter form without --enable prefix, --disable variant doesn't make sense, because it's disabled by default
        # option in autoconf's configure.ac is named --enable-sstatemirror (because it's created with AC_ARG_ENABLE macro)
        mirrors.add_argument('--sstatemirror', dest='sstatemirror', action='append',
                             help='set sstatemirror to specified URL, repeat this option if you want multiple sstate mirrors (default: None)')

        premirrorurl = mirrors.add_mutually_exclusive_group()
        default_premirror = 'http://downloads.yoctoproject.org/mirror/sources'
        premirrorurl.add_argument('--enable-default-premirror', dest='premirror', action='store_const', const=default_premirror, default="",
                                  help='enable default premirror URL (default: False)')
        # allow shorter form without --enable prefix, --disable variant doesn't make sense, because it's disabled by default
        # but keep also variant with --enable prefix so that we don't have to update config in existing jenkins jobs
        # option in autoconf's configure.ac is named --enable-premirror (because it's created with AC_ARG_ENABLE macro)
        premirrorurl.add_argument('--premirror', '--enable-premirror', dest='premirror', default='',
                                  help='set premirror to specified URL (default: None)')

        premirroronly = mirrors.add_mutually_exclusive_group()
        premirroronly.add_argument('--disable-fetch-premirror-only', dest='fetchpremirroronly', action='store_false', default=False,
                                   help='disable fetching through the network (default: False)')

        premirroronly.add_argument('--enable-fetch-premirror-only', dest='fetchpremirroronly', action='store_true', default=False,
                                   help='enable fetching through the network (default: True)')

        tarballs = mirrors.add_mutually_exclusive_group()
        tarballs.add_argument('--disable-generate-mirror-tarballs', dest='generatemirrortarballs', action='store_false', default=False,
                              help='disable tarball generation of fetched components (default: True)')

        tarballs.add_argument('--enable-generate-mirror-tarballs', dest='generatemirrortarballs', action='store_true', default=False,
                              help='generate tarballs suitable for mirroring (default: False)')

        private = mirrors.add_mutually_exclusive_group()
        private.add_argument('--disable-private-internal-component-mirror', dest='privateinternalcomponentmirror', action='store_false',
                          default=False, help='disable the private internal component mirror (default: disabled)')

        private.add_argument('--enable-private-internal-component-mirror', dest='privateinternalcomponentmirror', action='store_false',
                          default=False, help='enable the private internal component mirror (default: disabled). '+
                                              'This option is deprecated and ignored. It is left defined to avoid '+
                                              'breaking any existing scripts.')

        buildhistory = parser.add_argument_group('Buildhistory')

        buildhistory1 = buildhistory.add_mutually_exclusive_group()

        buildhistory1.add_argument('--disable-buildhistory', dest='buildhistory', action='store_false', default=True,
                                  help='disable buildhistory functionality (default: False)')

        buildhistory1.add_argument('--enable-buildhistory', dest='buildhistory', action='store_true', default=True,
                                  help='enable buildhistory functionality (default: True)')

        buildhistory.add_argument('--enable-buildhistoryauthor', dest='buildhistoryauthor', default='', help='specify name and email used in buildhistory git commits (default: none, will use author from git global config)')

        parser.add_argument('MACHINE', nargs='+')

    return parser.parse_args(arglist)

WEBOSLAYERS = []
LAYERSPRIORITY = {}
SUBMISSIONS = {}
LOCATIONS = {}
URLS = {}
PRIORITYORDER = []
COLLECTION_NAME = {}
COLLECTION_PATH = {}
DIRNAME = {}
SUMMARYINFO = {}
BRANCHINFONEW = {}
BRANCHINFOCURRENT = {}
COMMITIDSNEW = {}
COMMITIDSCURRENT = {}
TAGSINFONEW = {}
REPOPATCHDIR = {}

def _icecc_installed():
    msg = ''
    try:
        # Note that if package is not installed following call will throw an exception
        iceinstallstatus,iceversion = subprocess.check_output("dpkg-query -W icecc" ,
                                                           shell=True,
                                                           universal_newlines=True).split()
        # We are expecting icecc for the name
        if 'icecc' == iceinstallstatus:
             if '1.0.1-1' == iceversion:
                 return True, ''
             else:
                 msg =  "WARNING: Wrong icecc package version {} is installed, disabling build from using ICECC.\n".format(iceversion) + \
                        "Please check 'How To Install ICECC on Your Workstation (Client)'\n" + \
                        "http://wiki.lgsvl.com/pages/viewpage.action?pageId=96175316"
                 return False, msg
        else:
             msg = 'WARNING: ICECC package installation check failed, disabling build from using ICECC.'
             return False, msg

    except:
        msg = 'WARNING: ICECC package installation check failed, disabling build from using ICECC.'
        return False, msg

def location_to_dirname(layer, location):
    str1 = location.split('/')
    DIRNAME[layer] = os.path.splitext(str1[len(str1)-1])[0]

def readlayers(path):
    sys.path.insert(0,path)
    if not os.path.isfile(os.path.join(path,'weboslayers.py')):
        raise Exception("Error:" 'Configuration file {} does not exist!'.format(os.path.join(path,'weboslayers.py')))

    from weboslayers import webos_layers

    for p in webos_layers:
        WEBOSLAYERS.append(p[0])
        PRIORITYORDER.append(p[1])
        LAYERSPRIORITY[p[0]] = p[1]
        URLS[p[0]] = p[2]
        SUBMISSIONS[p[0]] = p[3]
        parsesubmissions(p[0])
        LOCATIONS[p[0]] = p[4]
        if URLS[p[0]]:
            location_to_dirname(p[0], URLS[p[0]])
        if LOCATIONS[p[0]]:
            location_to_dirname(p[0], LOCATIONS[p[0]])

    PRIORITYORDER.sort()
    PRIORITYORDER.reverse()

def parsesubmissions(layer):
    BRANCH = ''
    COMMIT = ''
    TAG = ''
    for vgit in SUBMISSIONS[layer].split(','):
        if not vgit:
            continue
        str1, str2 = vgit.split('=')
        if str1.lower() == 'commit':
            if not COMMIT:
                COMMIT = str2
        elif str1.lower() == 'branch':
            BRANCH = str2
        elif str1.lower() == 'tag':
            if not TAG:
                TAG = str2

    if not BRANCH:
        BRANCH = 'master'

    BRANCHINFONEW[layer] = BRANCH
    COMMITIDSNEW[layer] = COMMIT
    TAGSINFONEW[layer] = TAG

def readdistro(path):
    sys.path.insert(0,path)
    if not os.path.isfile(os.path.join(path,'weboslayers.py')):
        raise Exception("Error:" 'Configuration file {} does not exist!'.format(os.path.join(path,'weboslayers.py')))

    from weboslayers import Distribution
    return Distribution

def downloadprojects(srcdir,verbosity):
    for layer in WEBOSLAYERS:
        if os.path.exists(os.path.abspath( DIRNAME[layer] ) ):
            print("Note:", 'Git repo {} exists! Skipping download.'.format(layer))
            continue
        if URLS[layer] and LOCATIONS[layer]:
            raise Exception("Error:", 'Both url and location are defined for {} layer!'.format(layer))
        if not URLS[layer]:
            if not LOCATIONS[layer]:
                raise Exception("Error:", 'Must define {} git repo or location!'.format(layer))
            continue

        downloadrepo(layer)

def downloadrepo(layer,update=False):
    if not update:
        cmd = 'git clone {}'.format(URLS[layer])
        if echo_check_call(cmd,True):
            raise Exception('Error: running {}'.format(cmd))

        olddir = os.getcwd()
        os.chdir(DIRNAME[layer])
        newbranch = BRANCHINFONEW[layer]

        if newbranch:
            refbranchlist = str(subprocess.check_output(shlex.split(echo_cmd("git branch"))), encoding='utf-8', errors='strict')
            refbranch = refbranchlist.splitlines()
            foundbranch = False
            for ibranch in refbranch:
                if newbranch in ibranch:
                    foundbranch = True
            if not foundbranch:
                refbranchlist = str(subprocess.check_output(shlex.split(echo_cmd("git branch -r"))), encoding='utf-8', errors='strict')
                refbranch = refbranchlist.splitlines()
                for ibranch in refbranch:
                    if ibranch == "  %s/%s" % (REMOTE, newbranch):
                        foundbranch = True
                        print( " found %s " % ibranch )
                        cmd ='git checkout -B {0} {1}'.format(newbranch,ibranch)
                        if subprocess.call(shlex.split(echo_cmd(cmd))):
                            raise Exception('Can not checkout out [{}] branch'.format(newbranch))
                        break

        currentbranch = str(subprocess.check_output(shlex.split(echo_cmd("git rev-parse --abbrev-ref HEAD"))), encoding='utf-8', errors='strict').rstrip()
        newcommitid = COMMITIDSNEW[layer]
        if newcommitid:
            if newcommitid.startswith('refs/changes/'):
                if newbranch and newbranch != currentbranch:
                    # older git doesn't allow to update reference on currently checked out branch
                    cmd ='git fetch {0} {1} && git checkout -B {2} FETCH_HEAD'.format(REMOTE, newcommitid, newbranch)
                elif newbranch:
                    # we're already on requested branch
                    cmd ='git fetch {0} {1} && git reset --hard FETCH_HEAD'.format(REMOTE, newcommitid)
                else:
                    # we don't have any branch preference use detached
                    cmd ='git fetch {0} {1} && git checkout FETCH_HEAD'.format(REMOTE, newcommitid)
                if subprocess.call(echo_cmd(cmd), shell=True):
                    raise Exception('Can not checkout reference [{}]'.format(REMOTE, newcommitid))
            else:
                if newbranch and newbranch != currentbranch:
                    # older git doesn't allow to update reference on currently checked out branch
                    cmd ='git checkout -B {0} {1}'.format(newbranch,newcommitid)
                elif newbranch:
                    # we're already on requested branch
                    cmd ='git reset --hard {0}'.format(newcommitid)
                else:
                    # we don't have any branch preference use detached
                    cmd ='git checkout {0}'.format(newcommitid)
                if subprocess.call(shlex.split(echo_cmd(cmd))):
                    raise Exception('Can not checkout commit id [{}]'.format(newcommitid))

        newtag = TAGSINFONEW[layer]
        if newtag:
            if newbranch and newbranch != currentbranch:
                # older git doesn't allow to update reference on currently checked out branch
                cmd ='git checkout -B {0} {1}'.format(newbranch,newtag)
            elif newbranch:
                # we're already on requested branch
                cmd ='git reset --hard {}'.format(newtag)
            else:
                cmd ='git checkout {}'.format(newtag)
            if subprocess.call(shlex.split(echo_cmd(cmd))):
                raise Exception('Error: can not checkout tag [{}]'.format(newtag))

        os.chdir(olddir)
    else:
        updaterepo(layer)

def parselayerconffiles (layername, root):
    f = open(os.path.join(os.path.abspath(root), "conf", "layer.conf"), 'r')
    lines = f.readlines()
    f.close
    for line in lines:
        if re.search( 'BBFILE_COLLECTIONS.*=' , line):
            (dummy, collectionname) = line.rsplit('=')
            collectionname = collectionname.strip()
            collectionname = collectionname.strip("\"")
            COLLECTION_NAME[layername] = collectionname

def traversedir (root):
    for path, dirs, files in os.walk(root):
        for filename in files:
            if filename == 'layer.conf':
                ( collectionpath, dummy) = os.path.split(path)
                ( dymmy, layername) = os.path.split(collectionpath)
                parselayerconffiles(layername, collectionpath)
                COLLECTION_PATH[layername] = collectionpath
                break

def parseCollections (srcdir):
    for layer in WEBOSLAYERS:
        if ( URLS[layer] ):
            pathstr = DIRNAME[layer]
        if ( LOCATIONS[layer] ):
            pathstr = os.path.abspath( LOCATIONS[layer] )

        if ( os.path.exists( '{}'.format(pathstr)) ):
            traversedir(pathstr)
        else:
            raise Exception("Error:", 'directory does not exist {} !'.format(pathstr))

def writebblayersconf(sourcedir, machine):
    f = open(os.path.join(sourcedir, "BUILD-{0}".format(machine), "conf", "bblayers.conf"), 'a')
    f.write('\n')
    processed_layers = list()
    for p in PRIORITYORDER:
        for layer in LAYERSPRIORITY:
            if LAYERSPRIORITY[layer] == -1:
                continue
            if layer not in processed_layers:
                if LAYERSPRIORITY[layer] == p:
                    processed_layers.append(layer)
                    leftside = layer
                    leftside = leftside.replace('-','_')
                    leftside = leftside.upper()
                    if not URLS[layer]:
                        str = "{0}_LAYER ?= \"{1}\" ".format(leftside, LOCATIONS[layer])
                    else:
                        str = "{0}_LAYER ?= \"${{PALMDIR}}/{1}\"".format(leftside, COLLECTION_PATH[layer])

                    f.write(str)
                    f.write('\n')
                    break
    f.write('\n')
    f.write('BBFILES ?= ""\n')
    f.write('BBLAYERS ?= " \\')
    f.write('\n')
    processed_layers = list()
    for p in PRIORITYORDER:
        for layer in LAYERSPRIORITY:
            if LAYERSPRIORITY[layer] == -1:
                continue
            if layer not in processed_layers:
                if LAYERSPRIORITY[layer] == p:
                    processed_layers.append(layer)
                    leftside = layer
                    leftside = "{}".format(layer)
                    leftside = leftside.replace('-','_')
                    leftside = leftside.upper()
                    f.write("   ${{{0}_LAYER}} \\".format(leftside))
                    f.write('\n')
                    break
    f.write('  "')
    f.write('\n')
    for layer in LAYERSPRIORITY:
        if LAYERSPRIORITY[layer] <= 0 :
            continue
        f.write("BBFILE_PRIORITY_{0} = \"{1}\"".format(COLLECTION_NAME[layer], LAYERSPRIORITY[layer]))
        f.write('\n')
    f.close

def updatelayers (sourcedir):
    logger.info('MCF-%s: Updating build directory' % __version__)
    # all layers must exists before update
    for layer in WEBOSLAYERS:
        if not os.path.exists(os.path.abspath( DIRNAME[layer] ) ):
            downloadrepo(layer)

    # run sanity check on repo
    layers_sanity = list()
    update_location = list()
    updated_layers = list()
    for layer in WEBOSLAYERS:
        if DIRNAME[layer] not in update_location:
            update_location.append(DIRNAME[layer])
            updated_layers.append(layer)
            if reposanitycheck(layer) != 0:
                layers_sanity.append(layer)

    if layers_sanity:
        print('NOTE: Found local changes for repos(s) {0}\n'.format(layers_sanity))

    # update layers
    for layer in WEBOSLAYERS:
        if layer in updated_layers:
            downloadrepo(layer,True)

def printupdatesummary ():
    print ('\nRepo Update Summary')
    print ('===================')
    if not len(SUMMARYINFO):
         print ('No local changes found')
    for layer in SUMMARYINFO:
        mstatus = SUMMARYINFO[layer]
        print ('[{}] has the following changes:'.format(layer))
        if int(mstatus) & 1:
            print ('    *) local uncommitted changes, use \'git stash pop\' to retrieve')
        if int(mstatus) & 2:
            print ('    *) local committed changes, patches are backed up in {}/'.format(REPOPATCHDIR[layer]))
        if int(mstatus) & 4:
            print ('    *) local untracked changes')
        if BRANCHINFONEW[layer] != BRANCHINFOCURRENT[layer]:
            print ('    *) switched branches from {0} to {1}'.format(BRANCHINFOCURRENT[layer], BRANCHINFONEW[layer]))
    print ('\n')

def reposanitycheck(layer):
    olddir = os.getcwd()
    os.chdir(DIRNAME[layer])

    # Sync with remote repo
    if subprocess.call(shlex.split(echo_cmd('git remote update'))):
        raise Exception('Failed to fetch {} repo'.format(layer))

    BRANCHINFOCURRENT[layer] = str(subprocess.check_output(shlex.split(echo_cmd("git rev-parse --abbrev-ref HEAD"))), encoding='utf-8', errors='strict').rstrip()

    res = False
    msgs = 0

    if CLEAN:
        if subprocess.check_output(shlex.split(echo_cmd("git status --porcelain -s"))):
            print('Warning: Removing all local changes and untracked files in [{0}]'.format(layer))
            # abort rebase if git pull --rebase from update_layers got stuck on some local commit
            try:
                subprocess.check_output(shlex.split(echo_cmd("git rebase --abort")))
            except subprocess.CalledProcessError:
                # we can ignore this one
                pass
  
            subprocess.check_output(shlex.split(echo_cmd("git stash clear")))
            subprocess.check_output(shlex.split(echo_cmd("git clean -fdx")))
            subprocess.check_output(shlex.split(echo_cmd("git reset --hard")))
    else:
        print('Checking for local changes in [{0}]'.format(layer))
        if subprocess.check_output(shlex.split(echo_cmd("git status --porcelain --u=no -s"))):
            print('Warning: found local uncommited changes in [{0}]'.format(layer))
            msgs += 1
            subprocess.check_output(shlex.split(echo_cmd("git stash")))
            res = True

        if subprocess.check_output(echo_cmd("git status --porcelain -s | grep -v '^?? MCF-PATCHES_' || true"), shell=True):
            print('Warning: found local untracked changes in [{0}]'.format(layer))
            msgs += 4
            res = True

    try:
        remote = echo_check_call2('git remote | grep "^%s$"' % REMOTE)
    except subprocess.CalledProcessError:
        remote = ''

    if not remote:
        logger.error("Layer %s doesn't have the remote '%s'" % (layer, REMOTE))
        raise Exception("Layer %s doesn't have the remote '%s'" % (layer, REMOTE))

    try:
        urlcurrent = echo_check_call2("git config remote.%s.url" % REMOTE)
    except subprocess.CalledProcessError:
        # git config returns 1 when the option isn't set
        urlcurrent = ''
        pass

    # there is extra newline at the end
    urlcurrent = urlcurrent.strip()

    logger.debug("reposanitycheck(%s) dir %s, branchinfo %s, branchinfonew %s, url %s, urlnew %s" % (layer, DIRNAME[layer], BRANCHINFOCURRENT[layer], BRANCHINFONEW[layer], URLS[layer], urlcurrent))

    if urlcurrent != URLS[layer]:
        logger.warn("Changing url for remote '%s' from '%s' to '%s'" % (REMOTE, urlcurrent, URLS[layer]))
        echo_check_call2("git remote set-url %s %s" % (REMOTE, URLS[layer]))
        # Sync with new remote repo
        if subprocess.call(shlex.split(echo_cmd('git remote update'))):
            raise Exception('Failed to fetch {} repo'.format(layer))


    newbranch = BRANCHINFONEW[layer]
    if newbranch:
        refbranchlist = str(subprocess.check_output(shlex.split(echo_cmd("git branch"))), encoding='utf-8', errors='strict')
        refbranch = refbranchlist.splitlines()
        foundlocalbranch = False
        needcheckout = True
        for ibranch in refbranch:
            if ibranch == "  %s" % newbranch:
                foundlocalbranch = True
                break
            if ibranch == "* %s" % newbranch:
                foundlocalbranch = True
                needcheckout = False
                break

        refbranchlist = str(subprocess.check_output(shlex.split(echo_cmd("git branch -r"))), encoding='utf-8', errors='strict')
        refbranch = refbranchlist.splitlines()
        foundremotebranch = False
        for ibranch in refbranch:
            if ibranch == "  origin/%s" % newbranch:
                foundremotebranch = True
                remotebranch = ibranch.strip()
                break

        if foundlocalbranch and foundremotebranch:
            if needcheckout and subprocess.call(shlex.split(echo_cmd('git checkout {}'.format(newbranch)))):
                raise Exception('Failed git checkout {}'.format(newbranch))

            head = subprocess.check_output(shlex.split(echo_cmd("git rev-parse --abbrev-ref HEAD")))
            head = str(head, encoding='utf-8', errors='strict').rstrip()
            patchdir = './MCF-PATCHES_{0}-{1}'.format(head.replace('/','_'), timestamp)
            REPOPATCHDIR[layer] = "{0}/{1}".format(DIRNAME[layer], patchdir)
            cmd ='git format-patch {0}..{1} -o {2}'.format(remotebranch,newbranch,patchdir)
            rawpatches = str(subprocess.check_output(shlex.split(echo_cmd(cmd))), encoding='utf-8', errors='strict')
            patches = rawpatches.splitlines()
            num = len(patches)
            # print( ' info: number of patches: {0} '.format(num))
            if num > 0:
                msgs += 2
                res = True
            else:
                # remove empty dir if there weren't any patches created by format-patch
                cmd ='rmdir --ignore-fail-on-non-empty {0}'.format(patchdir)
                subprocess.check_output(shlex.split(echo_cmd(cmd)))

            # [GF-58476] As we already switched to newbranch, HEAD will always point to current.
            # This will allow us to work around the problem of having @ in the branch name
            trackingbranch = str(subprocess.check_output(shlex.split(echo_cmd("git rev-parse --abbrev-ref HEAD@{upstream}"))), encoding='utf-8', errors='strict')
            trackingbranch = trackingbranch.split()[0]
            if trackingbranch != remotebranch:
                # to ensure we are tracking remote
                if subprocess.call(shlex.split(echo_cmd('git branch --set-upstream {0} {1}'.format(newbranch, remotebranch)))):
                    raise Exception('Failed to set remote tracking on branch {}'.format(newbranch))

        elif not foundlocalbranch and foundremotebranch:
            if subprocess.call(shlex.split(echo_cmd('git checkout -b {0} {1}'.format(newbranch, remotebranch)))):
                raise Exception('Failed to checkout branch {}'.format(newbranch))
        else:
            # anything else is failure
            raise Exception('Could not find local and remote branches for {}'.format(newbranch))
    else:
            raise Exception('Undefined branch name')

    if res:
        SUMMARYINFO[layer] = msgs

    print('Done.\n')

    newdir = os.chdir(olddir)
    return res

# Taken from bitbake/lib/bb/fetch2/git.py with modifications for mcf usage
def contains_ref(tag):
    cmd = "git log --pretty=oneline -n 1 %s -- 2>/dev/null | wc -l" % (tag)
    output = str(subprocess.check_output(cmd, shell=True), encoding='utf-8', errors='strict')
    if len(output.split()) > 1:
        raise Exception("Error: '%s' gave output with more then 1 line unexpectedly, output: '%s'" % (cmd, output))
    return output.split()[0] != "0"

def updaterepo(layer):
    olddir = os.getcwd()
    os.chdir(DIRNAME[layer])

    COMMITIDSCURRENT[layer] = str(subprocess.check_output(shlex.split(echo_cmd("git  log --pretty=format:%h -1"))), encoding='utf-8', errors='strict')

    newcommitid = COMMITIDSNEW[layer]
    currentcommitid = COMMITIDSCURRENT[layer]
    newbranch = BRANCHINFONEW[layer]
    currentbranch = BRANCHINFOCURRENT[layer]

    logger.debug("updaterepo({0}) dir {1}, id {2}, newid {3}, branch {4}, newbranch {5}".format(layer, DIRNAME[layer], currentcommitid, newcommitid, currentbranch, newbranch))

    if newcommitid != currentcommitid:
        print('Updating [{0}]'.format(layer))
        if newcommitid:
            if newcommitid.startswith('refs/changes/'):
                if newbranch and newbranch != currentbranch:
                    # older git doesn't allow to update reference on currently checked out branch
                    cmd ='git fetch origin {0} && git checkout -B {1} FETCH_HEAD'.format(newcommitid,newbranch)
                elif newbranch:
                    # we're already on requested branch
                    cmd ='git fetch origin {0} && git reset --hard FETCH_HEAD'.format(newcommitid)
                else:
                    # we don't have any branch preference use detached
                    cmd ='git fetch origin {0} && git checkout FETCH_HEAD'.format(newcommitid)
                if subprocess.call(echo_cmd(cmd), shell=True):
                    raise Exception('Can not update to reference [{}]'.format(newcommitid))
            else:
                if not contains_ref(newcommitid):
                    if subprocess.call(shlex.split(echo_cmd('git fetch'))):
                        raise Exception('Error: git fetch failed for {}'.format(layer))
                if newbranch and newbranch != currentbranch:
                    # older git doesn't allow to update reference on currently checked out branch
                    cmd ='git checkout -B {0} {1}'.format(newbranch,newcommitid)
                elif newbranch:
                    # we're already on requested branch
                    cmd ='git reset --hard {0}'.format(newcommitid)
                else:
                    # we don't have any branch preference use detached
                    cmd ='git checkout {0}'.format(newcommitid)
                if subprocess.call(shlex.split(echo_cmd(cmd))):
                    raise Exception('Can not update to commit id [{}]'.format(newcommitid))
        else:
            if CLEAN:
                if subprocess.call(shlex.split(echo_cmd('git reset --hard origin/%s' % newbranch))):
                    raise Exception('Error: git reset --hard origin/%s' % newbranch)
            else:
                # current branch always tracks a remote one
                if subprocess.call(shlex.split(echo_cmd('git pull origin'))):
                    raise Exception('Error: git pull origin')
        print('Done.\n')
    else:
        print(('[{}] is up-to-date.'.format(layer)))

    newdir = os.chdir(olddir)
    os.getcwd()

def recover_current_mcf_state(srcdir, configure, origoptions):
    mcfstatusfile = os.path.join(srcdir, "mcf.status")
    if not os.path.exists(mcfstatusfile):
        raise Exception("mcf.status does not exist.")

    commandlinereconstructed = list()
    commandlinereconstructed.append(configure)
    start = False
    for line in open(mcfstatusfile,'r'):
        line = line.strip()
        if not start:
            start = line.startswith("exec")
            continue

        if start:
            if line.startswith('--'):
                line = line.rstrip('\\')
                line = line.strip(' ')
                line = line.replace('\"','')
                line = line.replace('\'','')
                commandlinereconstructed.append(line)
            else:
                lines = line.rstrip('\\')
                lines = lines.lstrip()
                lines = lines.rstrip()
                lines = lines.split()
                for lline in lines:
                    commandlinereconstructed.append(lline)

    sys.argv = commandlinereconstructed
    options = getopts()
    # always use trace/clean/verbose flags from origoptions not mcf.status
    options.trace = origoptions.trace
    options.clean = origoptions.clean
    options.verbose = origoptions.verbose
    return options


if __name__ == '__main__':
    # NB. The exec done by mcf.status causes argv[0] to be an absolute pathname
    progname = sys.argv[0]

    # Use the same timestamp for everything created by this invocation of mcf
    timestamp = strftime("%Y%m%d%H%M%S", gmtime())

    updatestate = False
    options = getopts()

    # Allow ../mcf to work.
    srcdir = os.path.dirname(progname)
    if not os.path.isabs(srcdir):
        lower_dirname = os.path.join('..', srcdir)
    else:
        lower_dirname = srcdir

    configure = os.path.join(lower_dirname, 'configure')

    if options.mcfcommand == 'update':
         # recover current mcf state
        updatestate = True
        options = recover_current_mcf_state(srcdir, configure, options)

    # read status template, process, write
    if options.trace:
        enable_debug()
    if options.clean:
        enable_clean()

    files = [[os.path.join(srcdir, 'build-templates', 'mcf-status.in'), 'mcf.status'],
             [os.path.join(srcdir, 'Makefile.in'), 'Makefile']]

    replacements = [
        ['@bb_number_threads@', '{}'.format(options.bb_number_threads)],
        ['@configure@', configure],
        ['@machines@', ' '.join(options.MACHINE)],
        ['@machines_only@', ' '.join([i.split(':')[0] for i in options.MACHINE])],
        ['@parallel_make@', '{}'.format(options.parallel_make)],
        ['@premirror@', options.premirror],
        ['@sstatemirror@', '"{}"'.format(' '.join(options.sstatemirror) if options.sstatemirror else '')],
        ['@distro@', '{}'.format(readdistro(srcdir))],
        ['@buildhistory@', '--{}-buildhistory'.format('enable' if options.buildhistory else 'disable')],
        ['@buildhistoryauthor@', options.buildhistoryauthor],
        ['@network@', '--{}-network'.format('enable' if options.network else 'disable')],
        ['@fetchpremirroronly@', '--{}-fetch-premirror-only'.format('enable' if options.fetchpremirroronly else 'disable')],
        ['@generatemirrortarballs@', '--{}-generate-mirror-tarballs'.format('enable'
                                                                            if options.generatemirrortarballs else 'disable')],
        ['@privateinternalcomponentmirror@', '--{}-private-internal-component-mirror'.format('enable'
                                                                            if options.privateinternalcomponentmirror else 'disable')],
        ['@prog@', progname],
        ['@srcdir@', srcdir],
        ]

    # if icecc is not installed, or version does not match requirements, then disabling icecc is the correct action.
    icestate, iceccinstallmsg = _icecc_installed()
    if icestate:
        icecc_disable_str = '--enable-icecc'
        if options.disable_icecc:
            icecc_disable_str = '--disable-icecc'
    else:
        icecc_disable_str = '--disable-icecc'

    icecc_replacements = [
        ['@icecc_disable_enable@', '{}'.format(icecc_disable_str)],
        ['@icecc_parallel_make@', '{}'.format(options.icecc_parallel_make)],
        ['@alternative_icecc_installation@', '{}'.format(options.icecc_location)],
        ['@icecc_user_package_blacklist@', '"{}"'.format(' '.join(options.icecc_user_package_blacklist) if options.icecc_user_package_blacklist else '')],
        ['@icecc_user_class_blacklist@', '"{}"'.format(' '.join(options.icecc_user_class_blacklist) if options.icecc_user_class_blacklist else '')],
        ['@icecc_user_package_whitelist@', '"{}"'.format(' '.join(options.icecc_user_package_whitelist) if options.icecc_user_package_whitelist else '')],
        ['@icecc_environment_script@', '{}'.format(options.icecc_env_exec)],
        ]

    replacements =  replacements + icecc_replacements

    for i, j in files:
        process_file(i, j, replacements)

    echo_check_call('/bin/chmod a+x mcf.status', options.verbose)

    readlayers(srcdir)
    if updatestate:
        updatelayers(srcdir)
        printupdatesummary()
    else:
        downloadprojects(srcdir,True)

    if iceccinstallmsg:
        print ("\n%s\n" % iceccinstallmsg)

    parseCollections(srcdir)

    for machine in options.MACHINE:
        logger.info('MCF-%s: Configuring build directory BUILD-%s' % (__version__, machine))
        logger.info('configure is {}'.format(configure))

        cmd = '([ -d BUILD-{} ] || mkdir BUILD-{})'.format(machine, machine)
        cmd += ' && (cd BUILD-{} && PWD= @configure@ \
            --enable-bb-number-threads=@bb_number_threads@ \
            --enable-parallel-make=@parallel_make@ \
            --enable-premirror=@premirror@ \
            --enable-sstatemirror=@sstatemirror@ \
            --enable-distro=@distro@ \
            @buildhistory@ \
            --enable-buildhistoryauthor="@buildhistoryauthor@" \
            @network@ \
            @fetchpremirroronly@ \
            @privateinternalcomponentmirror@ \
            @generatemirrortarballs@ \
            --build=ubuntu \
            {} \
            --enable-icecc-parallel-make=@icecc_parallel_make@ \
            --enable-icecc-location=@alternative_icecc_installation@ \
            --enable-icecc-user-package-blacklist=@icecc_user_package_blacklist@ \
            --enable-icecc-user-class-blacklist=@icecc_user_class_blacklist@ \
            --enable-icecc-user-package-whitelist=@icecc_user_package_whitelist@ \
            --enable-icecc-env-exec=@icecc_environment_script@ \
            --host={})'.format(machine, icecc_disable_str, machine)

        for i, j in replacements:
            cmd = cmd.replace(i, j)

        echo_check_call(cmd, options.verbose)

        writebblayersconf(srcdir, machine)

        logger.info('Done.\n')
